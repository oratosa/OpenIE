{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, email\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import tokenize\n",
    "import pprint, re, time\n",
    "\n",
    "pd.options.display.max_colwidth = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loadFile import getFileList, getDirList, fileToDataFrame\n",
    "\n",
    "# ディレクトリ 内のメールファイルを読み込む\n",
    "directory_path = \"wiki-research-l/2020-July\"\n",
    "file_list = getFileList(directory_path)\n",
    "\n",
    "# テキストファイルをデータフレームに格納する\n",
    "mail_df, thread_df = fileToDataFrame(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preProcess import cleaningText\n",
    "s_list = []\n",
    "for i,content in mail_df['Content'].items():\n",
    "    sentences = cleaningText(content)\n",
    "    s_list.append(sentences)\n",
    "mail_df['Cleaned_Content'] = s_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#　センテンスのリストを作る\n",
    "sentence_list = []\n",
    "for content in mail_df['Cleaned_Content']:\n",
    "    sentences = tokenize.sent_tokenize(content)\n",
    "    for sentence in sentences:\n",
    "        sentence_list.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{0: 9, 1: 7, 2: 3, 3: 18, 4: 12, 5: 30, 6: 24, 7: 24, 8: 25, 9: 14, 10: 70, 11: 14, 12: 19, 13: 31, 14: 2, 15: 2, 16: 13, 17: 2, 18: 25, 19: 49, 20: 10, 21: 24, 22: 11, 23: 14, 24: 15, 25: 21, 26: 40, 27: 4, 28: 4, 29: 1, 30: 27, 31: 5, 32: 18, 33: 2, 34: 30, 35: 21, 36: 34, 37: 42, 38: 25, 39: 18, 40: 10, 41: 18, 42: 10, 43: 6, 44: 21, 45: 13, 46: 17, 47: 2, 48: 23, 49: 23, 50: 7, 51: 42, 52: 14, 53: 10, 54: 52, 55: 13, 56: 23, 57: 3, 58: 7, 59: 19, 60: 3, 61: 6, 62: 11, 63: 15, 64: 5, 65: 11, 66: 16, 67: 30, 68: 37, 69: 24, 70: 4, 71: 34, 72: 110, 73: 34, 74: 24, 75: 10, 76: 54, 77: 41, 78: 136, 79: 49, 80: 1, 81: 17, 82: 13, 83: 24, 84: 53, 85: 3, 86: 3, 87: 39, 88: 13, 89: 14, 90: 21, 91: 25, 92: 15, 93: 15, 94: 15, 95: 19, 96: 1, 97: 22, 98: 6, 99: 26, 100: 13, 101: 2, 102: 5, 103: 9, 104: 51, 105: 27, 106: 87, 107: 24, 108: 58, 109: 46, 110: 36, 111: 24, 112: 51, 113: 15, 114: 24, 115: 15, 116: 18, 117: 56, 118: 36, 119: 15, 120: 27, 121: 60, 122: 5, 123: 128, 124: 15, 125: 122, 126: 51, 127: 36, 128: 12, 129: 26, 130: 26, 131: 12, 132: 31, 133: 40, 134: 39, 135: 47, 136: 39, 137: 57, 138: 28, 139: 40, 140: 41, 141: 19, 142: 36, 143: 22, 144: 113, 145: 34, 146: 50, 147: 90, 148: 38, 149: 266, 150: 31, 151: 24, 152: 31, 153: 22, 154: 7, 155: 10, 156: 310, 157: 50, 158: 25, 159: 20, 160: 27, 161: 12, 162: 5, 163: 8, 164: 117, 165: 7, 166: 5, 167: 10, 168: 1, 169: 15, 170: 45, 171: 1, 172: 19, 173: 4, 174: 19, 175: 22, 176: 21, 177: 21, 178: 12, 179: 3, 180: 29, 181: 21, 182: 22, 183: 4, 184: 7, 185: 27, 186: 37, 187: 22, 188: 20, 189: 28, 190: 14, 191: 15, 192: 6, 193: 3, 194: 3, 195: 54, 196: 18, 197: 137, 198: 1, 199: 170, 200: 13, 201: 11, 202: 25, 203: 30, 204: 14, 205: 13, 206: 29, 207: 28, 208: 14, 209: 14, 210: 60, 211: 23, 212: 15, 213: 21, 214: 30, 215: 7, 216: 20, 217: 2, 218: 5, 219: 10, 220: 13, 221: 26, 222: 4, 223: 14, 224: 19, 225: 9, 226: 27, 227: 10, 228: 211, 229: 27, 230: 15, 231: 45, 232: 55, 233: 41, 234: 29, 235: 34, 236: 15, 237: 27, 238: 60, 239: 5, 240: 128, 241: 15, 242: 122, 243: 51, 244: 36, 245: 12, 246: 26, 247: 26, 248: 12, 249: 31, 250: 40, 251: 39, 252: 47, 253: 39, 254: 57, 255: 28, 256: 40, 257: 41, 258: 19, 259: 36, 260: 22, 261: 113, 262: 34, 263: 50, 264: 90, 265: 38, 266: 266, 267: 31, 268: 24, 269: 31, 270: 22, 271: 7, 272: 10, 273: 310, 274: 24, 275: 44, 276: 52, 277: 2, 278: 18, 279: 19, 280: 31, 281: 29, 282: 13, 283: 30, 284: 13, 285: 62, 286: 24, 287: 37, 288: 51, 289: 28, 290: 42, 291: 17, 292: 2, 293: 14, 294: 10, 295: 15, 296: 13, 297: 44, 298: 27, 299: 13, 300: 15, 301: 22, 302: 27, 303: 27, 304: 30, 305: 51, 306: 48, 307: 22, 308: 26, 309: 17, 310: 19, 311: 207, 312: 10, 313: 10, 314: 25, 315: 25, 316: 138, 317: 49, 318: 10, 319: 34, 320: 3, 321: 25, 322: 29, 323: 27, 324: 23, 325: 1, 326: 25, 327: 41, 328: 28, 329: 10, 330: 19, 331: 21, 332: 12, 333: 26, 334: 32, 335: 34, 336: 40, 337: 33, 338: 38, 339: 22, 340: 34, 341: 33, 342: 15, 343: 32, 344: 16, 345: 78, 346: 27, 347: 41, 348: 62, 349: 31, 350: 72, 351: 6, 352: 27, 353: 20, 354: 10, 355: 9, 356: 4, 357: 6, 358: 2}\n"
    }
   ],
   "source": [
    "sent_length = {}\n",
    "for i, sentence in enumerate(sentence_list):\n",
    "    sent_length[i] = len(sentence.split())\n",
    "print(sent_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'> > > > Please fill this form to register for CICM 2020: > > > >                  https://forms.gle/oS5BVGDf6LgDGDiK8 > > > > > > SCIENTIFIC PROGRAM > > ------------------ > > > > The program of the conference is available under: > > > >              https://easychair.org/smart-program/CICM-13/ > > > > (all times are in CEST timezone (UTC+2)) > > > > > > INVITED SPEAKERS > > ------------------------ > > > > - Kevin Buzzard, Imperial College, London, UK > >   Formalizing Undergraduate Mathematics > > > > - Catherine Dubois, ENSIIE, CNRS, Evry, France > >   Formally Verified Constraints Solvers: a Guided Tour > > > > - Christian Szegedy, Google Research, Mountain View, CA, USA > >   A Promising  Path Towards  Autoformalization and  General Artificial > >   Intelligence > > > > > > INVITED WORKSHOP SPEAKERS > > ------------------------- > > > > - Freek Wiedijk, Radboud University Nijmegen, NL > >   Formal Proof for the Future > > > > - Fairouz Kamareddine, Heriot-Watt University, UK > >   TBA > > > > > > > > AFFILIATED WORKSHOPS AND DOCTORAL PROGRAMME > > --------------------------------------- > > > > - NFM 2020 - Workshop on Natural Formal Mathematics > >   (https://cicm-conference.org/2020/cicm.php?event=NFM) > > > > - Doctoral Programme > >   (https://cicm-conference.org/2020/cicm.php?event=doctoral) > > > > > > > > ------------------------------ > > > > Subject: Digest Footer > > > > _______________________________________________ > > Wiki-research-l mailing list > > Wiki-research-l at lists.wikimedia.org > > https://lists.wikimedia.org/mailman/listinfo/wiki-research-l > > > > > > ------------------------------ > > > > End of Wiki-research-l Digest, Vol 179, Issue 7 > > *********************************************** > > > > > -- > Mackenzie Lemieux > mackenzie.lemieux at gmail.com > cell: 416-806-0041 > 220 Gilmour Avenue > Toronto, Ontario > M6P 3B4 > _______________________________________________ > Wiki-research-l mailing list > Wiki-research-l at lists.wikimedia.org > https://lists.wikimedia.org/mailman/listinfo/wiki-research-l >'"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "sentence_list[156]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_length = sorted(sent_length.items(), key=lambda x:x[1], reverse=True)\n",
    "sent_cnt_list = []\n",
    "for tpl in id_length:\n",
    "    sent_cnt_list.append([tpl[0],tpl[1],sentence_list[tpl[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_cnt_df = pd.DataFrame(sent_cnt_list, columns=('idx','cnt','sentence'))\n",
    "sent_cnt_df.to_csv('analysis/output/sent_cnt_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OpenIEにかける\n",
    "from pyopenie import OpenIE5\n",
    "extractor = OpenIE5('http://localhost:8000')\n",
    "\n",
    "extractions_list = []\n",
    "for sentence in sentence_list:\n",
    "    try:\n",
    "        extractions = extractor.extract(sentence)\n",
    "        extractions_list.append(extractions)\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rows = []\n",
    "for extractions in extractions_list:\n",
    "    if extractions == []:\n",
    "        pass\n",
    "    else:\n",
    "        for extraction in extractions:\n",
    "            sentence = extraction['sentence']\n",
    "            confidence = extraction['confidence']\n",
    "            arg1 = extraction['extraction']['arg1']['text']\n",
    "            rel = extraction['extraction']['rel']['text']\n",
    "            arg2s_list = []\n",
    "            for arg2 in extraction['extraction']['arg2s']:\n",
    "                arg2s_list.append(arg2['text'])\n",
    "            arg2s = ' '.join(map(str, arg2s_list))\n",
    "            row = [sentence, arg1, rel, arg2s, confidence]\n",
    "            rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "853"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "kb_df = pd.DataFrame(rows, columns = ['sentence', 'arg1', 'rel', 'arg2s', 'confidence'])\n",
    "len(kb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from db import connect\n",
    "engine = connect()\n",
    "kb_df.to_sql(name='kb_wiki_research_l',con=engine,if_exists='replace',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}