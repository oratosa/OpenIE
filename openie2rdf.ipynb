{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, email, datetime, pprint, re, time, html, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.metrics import *\n",
    "\n",
    "pd.options.display.max_colwidth = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 自然言語処理\n",
    "import spacy \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "from spacy.pipeline import Sentencizer\n",
    "sentencizer = Sentencizer()\n",
    "nlp.add_pipe(sentencizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/taroaso/myprojects/OpenIE/trec/output/tagme.pickle', mode=\"rb\") as f:\n",
    "    tagme_result = pickle.load(f)\n",
    "\n",
    "with open('/Users/taroaso/myprojects/OpenIE/trec/output/ner.pickle', mode=\"rb\") as f:\n",
    "    ner_result = pickle.load(f)\n",
    "\n",
    "with open('/Users/taroaso/myprojects/OpenIE/trec/output/type_translation.pickle', mode=\"rb\") as f:\n",
    "    translation = pickle.load(f)\n",
    "\n",
    "with open('/Users/taroaso/myprojects/OpenIE/trec/output/openie_result.pickle', mode=\"rb\") as f:\n",
    "    openie = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from db import connect\n",
    "engine = connect()\n",
    "mail_df = pd.read_sql(sql='SELECT DISTINCT id, body FROM mail',con=engine, index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "to_array() takes exactly one argument (0 given)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-28c0baa01159>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmail_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmail_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'4084867E.9050502@kbc.net.au'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0marray_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_doc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: to_array() takes exactly one argument (0 given)"
     ]
    }
   ],
   "source": [
    "doc = nlp(mail_df[mail_df['id']=='4084867E.9050502@kbc.net.au']['body'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('Jesper Tverskov writes:\\n One of the recommendations from City University on the WAI Guidelines said:\\n - improve search design \\n<content trimmed/>\\n ', 0, 29)\n(\"Now, from the point of view of accessibility, when a website's pages are indexed by Google, wouldn't it be easier for people with disabilities to use a seach engine they are already used to use?\", 29, 70)\n('Should we actively promote the use of search engines like Google as local seach engine at any major website, if the pages are already indexed by Google?', 70, 99)\n('\\n', 99, 100)\n('Matthew Smith replies:\\n', 100, 105)\n('Whilst I think that Google has a great product, I do not think it in the best \\ninterests of accessibility, or indeed of a stable infrastructure, to standardise \\non a single, proprietary solution.', 105, 145)\n('\\n', 145, 146)\n('If Google should fail as a company or start charging excessively for the Site \\nSearch service), if everyone were using it, the entire concept of Site Search \\nwould drop into a vacuum.', 146, 184)\n('\\n', 184, 185)\n('Were Google an Open Source project, with a distributed infrastructure', 185, 196)\n('ie: not \\nall owned by Google), I might feel otherwise.', 196, 211)\n('\\n', 211, 212)\n('Having said this, widespread use of the Google \"look and feel\" may be helpful by \\nproviding a consistent, familiar, interface IF Google has truly the paragon of \\naccessible search interfaces.', 212, 250)\n('\\n', 250, 251)\n('Cheers\\n', 251, 253)\n('M\\n-- \\n', 253, 257)\n('Matthew Smith\\n', 257, 260)\n('Kadina Business Consultancy\\n', 260, 264)\n('South Australia\\n', 264, 267)\n('http://www.kbc.net.au', 267, 268)\n"
     ]
    }
   ],
   "source": [
    "test = {}\n",
    "for sent in doc.sents:\n",
    "    print((sent.text,sent.start,sent.end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'facts': [{'subject': 'website', 'predicate': 'has', 'object': 'pages'},\n",
       "   {'subject': \"website 's pages\",\n",
       "    'predicate': 'are indexed by',\n",
       "    'object': 'Google'},\n",
       "   {'subject': 'it', 'predicate': 'be', 'object': 'easier'},\n",
       "   {'subject': 'it',\n",
       "    'predicate': 'be easier from',\n",
       "    'object': 'point of view of accessibility'},\n",
       "   {'subject': 'it',\n",
       "    'predicate': 'be easier for',\n",
       "    'object': 'people with disabilities to use seach engine'},\n",
       "   {'subject': 'disabilities',\n",
       "    'predicate': 'be use',\n",
       "    'object': 'seach engine'},\n",
       "   {'subject': 'they',\n",
       "    'predicate': 'are used to use',\n",
       "    'object': 'seach engine already'},\n",
       "   {'subject': 'they',\n",
       "    'predicate': 'are used to use',\n",
       "    'object': 'seach engine'}]},\n",
       " {'facts': [{'subject': 'Google',\n",
       "    'predicate': 'is',\n",
       "    'object': 'search engine'},\n",
       "   {'subject': 'we', 'predicate': 'promote use of', 'object': 'Google'},\n",
       "   {'subject': 'we',\n",
       "    'predicate': 'promote use of Google as local seach engine at',\n",
       "    'object': 'QUANT_O_1 major website'},\n",
       "   {'subject': 'pages', 'predicate': 'are indexed by', 'object': 'Google'}]},\n",
       " {'facts': [{'subject': 'Google',\n",
       "    'predicate': 'has',\n",
       "    'object': 'great product'},\n",
       "   {'subject': 'Google', 'predicate': 'has', 'object': 'great product'},\n",
       "   {'subject': 'I', 'predicate': 'do think', 'object': 'it'}]},\n",
       " {'facts': [{'subject': 'Google', 'predicate': 'fail as', 'object': 'company'},\n",
       "   {'subject': 'Google',\n",
       "    'predicate': 'start',\n",
       "    'object': 'charging excessively'},\n",
       "   {'subject': 'Site', 'predicate': 'Search', 'object': 'service'},\n",
       "   {'subject': 'everyone', 'predicate': 'were using', 'object': 'it'},\n",
       "   {'subject': 'entire concept of Site',\n",
       "    'predicate': 'Search drop into',\n",
       "    'object': 'vacuum'}]},\n",
       " {'facts': [{'subject': 'I', 'predicate': 'feel', 'object': 'otherwise'}]}]"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "openie['4084867E.9050502@kbc.net.au']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "oie_triples = []\n",
    "for uid in openie.keys():\n",
    "    # トリプルの抽出結果とエンティティの抽出結果があるときのみ,処理を継続する\n",
    "    if openie[uid] != [] and tagme_result[uid] is not None:\n",
    "        # メールごとにopenIEで抽出された複数のトリプルを取得する\n",
    "        for oie in openie[uid]:\n",
    "            # トリプルを走査する\n",
    "            for fact in oie['facts']:\n",
    "                # tagmeのアノテーション結果を走査する\n",
    "                for annotation in tagme_result[uid]['annotations']:         \n",
    "                    # トリプルの主語と一致するspotがある場合，トリプル（主語，メンション，検出されたスポットのリソース）作成\n",
    "                    if annotation['spot'] == fact['subject'] and annotation['link_probability'] >= 0.3: \n",
    "                        emailmessage = uid\n",
    "                        #emailmessage = re.sub(r'[^a-zA-Z_0-9]','_',uid)\n",
    "                        start = annotation['start']\n",
    "                        end = annotation['end']\n",
    "                        offset_based_string = emailmessage + '#offset_' + str(start) + '_' + str(end)\n",
    "                        oie_triples.append((fact['subject'],'mentions',offset_based_string))\n",
    "                        #　トリプルの目的語と一致するspotがある場合，（目的語，メンション，検出されたスポットのリソース）作成\n",
    "                        for annotation in tagme_result[uid]['annotations']: \n",
    "                            if annotation['spot'] == fact['object'] and annotation['link_probability'] >= 0.3:\n",
    "                                start = annotation['start']\n",
    "                                end = annotation['end']\n",
    "                                offset_based_string = emailmessage + '#offset_' + str(start) + '_' + str(end)\n",
    "                                test.append((fact['object'],'mentions',offset_based_string))\n",
    "                            else:\n",
    "                                pass\n",
    "                        #openIEのトリプル作成\n",
    "                        oie_triples.append((fact['subject'],fact['predicate'],fact['object']))\n",
    "                    else:\n",
    "                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1320"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "len(oie_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}