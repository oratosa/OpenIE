{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, email\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import pprint, re, time\n",
    "\n",
    "pd.options.display.max_colwidth = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loadFile import getFileList, getDirList, fileToDataFrame\n",
    "\n",
    "# ディレクトリ 内のメールファイルを読み込む\n",
    "directory_path = \"wiki-research-l/2020-July\"\n",
    "file_list = getFileList(directory_path)\n",
    "file_list.sort()\n",
    "\n",
    "# テキストファイルをデータフレームに格納する\n",
    "mail_df, thread_df = fileToDataFrame(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# メールのBody部分を各パートに分解する\n",
    "bodies = dict(Bodies=[])\n",
    "for idx, body in mail_df.loc[:,'Body'].items():\n",
    "    origin = []\n",
    "    greetings = dict(Greetings=[])\n",
    "    sentences = dict(Sentence=[])\n",
    "    captions = dict(Caption=[])\n",
    "    bulletlist = dict(Bulletlist=[])\n",
    "    ending = dict(Ending=[])\n",
    "    quotation = dict(Quotation=[])\n",
    "    footer = dict(Footer=[])\n",
    "    misc = dict(Misc=[])\n",
    "\n",
    "    lines = body.splitlines()\n",
    "    for num, line in enumerate(lines):\n",
    "        if re.match(r'\\[G\\]',line) is not None:\n",
    "            greetings['Greetings'].append({num:line[3:]})\n",
    "            origin.append(line[3:])\n",
    "        elif re.match(r'\\[S\\]',line) is not None:\n",
    "            sentences['Sentence'].append({num:line[3:]})\n",
    "            origin.append(line[3:])\n",
    "        elif re.match(r'\\[C\\]',line) is not None:\n",
    "            captions['Caption'].append({num:line[3:]})\n",
    "            origin.append(line[3:])\n",
    "        elif re.match(r'\\[B\\]',line) is not None:\n",
    "            bulletlist['Bulletlist'].append({num:line[3:]})\n",
    "            origin.append(line[3:])\n",
    "        elif re.match(r'\\[E\\]',line) is not None:\n",
    "            ending['Ending'].append({num:line[3:]})\n",
    "            origin.append(line[3:])\n",
    "        elif re.match(r'\\[Q\\]',line) is not None:\n",
    "            quotation['Quotation'].append({num:line[3:]})\n",
    "            origin.append(line[3:])\n",
    "        elif re.match(r'\\[F\\]',line) is not None:\n",
    "            footer['Footer'].append({num:line[3:]})\n",
    "            origin.append(line[3:])\n",
    "        elif re.match(r'\\[M\\]',line) is not None:\n",
    "            misc['Misc'].append({num:line[3:]})\n",
    "            origin.append(line[3:])\n",
    "        else: #空白行に対応する\n",
    "            continue\n",
    "    originbody = ' '.join(origin)\n",
    "    bodies['Bodies'].append({'idx':idx, 'countrows':len(lines), 'body':originbody, **greetings, **sentences, **captions, **bulletlist, **ending, **quotation, **footer, **misc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#　bodiesのsentenceのvalueから複数文のテキストを作る\n",
    "s_list = []\n",
    "for i in bodies['Bodies']:  #1通ずつ取り出す\n",
    "    text = ''\n",
    "    for j in i['Sentence']: #1行{行番号:文}ずつ取り出し，複数文が含まれた1つの文字列にする\n",
    "        text = text + list(j.values())[0] + ' '\n",
    "    s_list.append(text) #1通ごとの自然文のテキストをリストに格納する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# センテンスのdataframeを作る\n",
    "sentence_list = []\n",
    "# 文章全体に対する前処理\n",
    "for i, content in enumerate(s_list):\n",
    "    sentences = tokenize.sent_tokenize(content)\n",
    "    # 文に対する前処理\n",
    "    for j, sentence in enumerate(sentences):\n",
    "        sentence = re.sub(r'\\s{2,}',' ',sentence)\n",
    "        sentence_list.append([mail_df['Message-ID'][i],sentence])\n",
    "sentence_df = pd.DataFrame(sentence_list,columns=['Message-ID','sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                             Message-ID  \\\n0  <CAE4fJj-un1Um+3aE1jTe9b8WQZuFLMaaFmCJ9zNtzTkuUja0Rw@mail.gmail.com>   \n1  <CAE4fJj-un1Um+3aE1jTe9b8WQZuFLMaaFmCJ9zNtzTkuUja0Rw@mail.gmail.com>   \n2  <CAE4fJj-un1Um+3aE1jTe9b8WQZuFLMaaFmCJ9zNtzTkuUja0Rw@mail.gmail.com>   \n3  <CAE4fJj-un1Um+3aE1jTe9b8WQZuFLMaaFmCJ9zNtzTkuUja0Rw@mail.gmail.com>   \n4  <CAE4fJj_b7k8yeqmz19a-seo3gtL9Mg1nvQO0oPUtrxvCFMkEaw@mail.gmail.com>   \n\n                                                                                                          sentence  \n0                                                                                           Thanks for your reply!  \n1  It's a great suggestion to include a list of ORES based tools for people who are not familiar with ORES itself.  \n2                                    For our research, we would love to interview you and test our visualizations.  \n3                               Please let me know what times will work best for you so we can schedule a meeting.  \n4                                                                                           Thanks for clarifying.  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Message-ID</th>\n      <th>sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;CAE4fJj-un1Um+3aE1jTe9b8WQZuFLMaaFmCJ9zNtzTkuUja0Rw@mail.gmail.com&gt;</td>\n      <td>Thanks for your reply!</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;CAE4fJj-un1Um+3aE1jTe9b8WQZuFLMaaFmCJ9zNtzTkuUja0Rw@mail.gmail.com&gt;</td>\n      <td>It's a great suggestion to include a list of ORES based tools for people who are not familiar with ORES itself.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;CAE4fJj-un1Um+3aE1jTe9b8WQZuFLMaaFmCJ9zNtzTkuUja0Rw@mail.gmail.com&gt;</td>\n      <td>For our research, we would love to interview you and test our visualizations.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;CAE4fJj-un1Um+3aE1jTe9b8WQZuFLMaaFmCJ9zNtzTkuUja0Rw@mail.gmail.com&gt;</td>\n      <td>Please let me know what times will work best for you so we can schedule a meeting.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;CAE4fJj_b7k8yeqmz19a-seo3gtL9Mg1nvQO0oPUtrxvCFMkEaw@mail.gmail.com&gt;</td>\n      <td>Thanks for clarifying.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "#sentence_df.to_csv('wiki-research-l/output/sentence_df.csv')\n",
    "sentence_df = pd.read_csv('/Users/taroaso/myprojects/OpenIE/wiki-research-l/output/sentence_df.csv',index_col=0)\n",
    "sentence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                             message_id  \\\n0  <CAE4fJj-un1Um+3aE1jTe9b8WQZuFLMaaFmCJ9zNtzTkuUja0Rw@mail.gmail.com>   \n1  <CAE4fJj-un1Um+3aE1jTe9b8WQZuFLMaaFmCJ9zNtzTkuUja0Rw@mail.gmail.com>   \n2  <CAE4fJj-un1Um+3aE1jTe9b8WQZuFLMaaFmCJ9zNtzTkuUja0Rw@mail.gmail.com>   \n3  <CAE4fJj-un1Um+3aE1jTe9b8WQZuFLMaaFmCJ9zNtzTkuUja0Rw@mail.gmail.com>   \n4  <CAE4fJj-un1Um+3aE1jTe9b8WQZuFLMaaFmCJ9zNtzTkuUja0Rw@mail.gmail.com>   \n\n                                                                                                          sentence  \\\n0  It's a great suggestion to include a list of ORES based tools for people who are not familiar with ORES itself.   \n1  It's a great suggestion to include a list of ORES based tools for people who are not familiar with ORES itself.   \n2  It's a great suggestion to include a list of ORES based tools for people who are not familiar with ORES itself.   \n3                                    For our research, we would love to interview you and test our visualizations.   \n4                                    For our research, we would love to interview you and test our visualizations.   \n\n                 arg1                 rel  \\\n0              people             are not   \n1  a great suggestion          to include   \n2                  It                  's   \n3                  we  would love to test   \n4                  we          would love   \n\n                                                                 arg2s  \\\n0                                                   familiar with ORES   \n1                                a list of ORES based tools for people   \n2  a great suggestion to include a list of ORES based tools for people   \n3                                                   our visualizations   \n4                          to test our visualizations For our research   \n\n   confidence            new_arg1             new_rel  \\\n0    0.895843              people             are not   \n1    0.925061  a great suggestion          to include   \n2    0.678369                  It                  's   \n3    0.256095            Ethan Ye  would love to test   \n4    0.380779            Ethan Ye          would love   \n\n                                                             new_arg2s  \n0                                                   familiar with ORES  \n1                                a list of ORES based tools for people  \n2  a great suggestion to include a list of ORES based tools for people  \n3                                            Ethan Ye's visualizations  \n4            to test Ethan Ye's visualizations For Ethan Ye's research  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>message_id</th>\n      <th>sentence</th>\n      <th>arg1</th>\n      <th>rel</th>\n      <th>arg2s</th>\n      <th>confidence</th>\n      <th>new_arg1</th>\n      <th>new_rel</th>\n      <th>new_arg2s</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;CAE4fJj-un1Um+3aE1jTe9b8WQZuFLMaaFmCJ9zNtzTkuUja0Rw@mail.gmail.com&gt;</td>\n      <td>It's a great suggestion to include a list of ORES based tools for people who are not familiar with ORES itself.</td>\n      <td>people</td>\n      <td>are not</td>\n      <td>familiar with ORES</td>\n      <td>0.895843</td>\n      <td>people</td>\n      <td>are not</td>\n      <td>familiar with ORES</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;CAE4fJj-un1Um+3aE1jTe9b8WQZuFLMaaFmCJ9zNtzTkuUja0Rw@mail.gmail.com&gt;</td>\n      <td>It's a great suggestion to include a list of ORES based tools for people who are not familiar with ORES itself.</td>\n      <td>a great suggestion</td>\n      <td>to include</td>\n      <td>a list of ORES based tools for people</td>\n      <td>0.925061</td>\n      <td>a great suggestion</td>\n      <td>to include</td>\n      <td>a list of ORES based tools for people</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;CAE4fJj-un1Um+3aE1jTe9b8WQZuFLMaaFmCJ9zNtzTkuUja0Rw@mail.gmail.com&gt;</td>\n      <td>It's a great suggestion to include a list of ORES based tools for people who are not familiar with ORES itself.</td>\n      <td>It</td>\n      <td>'s</td>\n      <td>a great suggestion to include a list of ORES based tools for people</td>\n      <td>0.678369</td>\n      <td>It</td>\n      <td>'s</td>\n      <td>a great suggestion to include a list of ORES based tools for people</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;CAE4fJj-un1Um+3aE1jTe9b8WQZuFLMaaFmCJ9zNtzTkuUja0Rw@mail.gmail.com&gt;</td>\n      <td>For our research, we would love to interview you and test our visualizations.</td>\n      <td>we</td>\n      <td>would love to test</td>\n      <td>our visualizations</td>\n      <td>0.256095</td>\n      <td>Ethan Ye</td>\n      <td>would love to test</td>\n      <td>Ethan Ye's visualizations</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;CAE4fJj-un1Um+3aE1jTe9b8WQZuFLMaaFmCJ9zNtzTkuUja0Rw@mail.gmail.com&gt;</td>\n      <td>For our research, we would love to interview you and test our visualizations.</td>\n      <td>we</td>\n      <td>would love</td>\n      <td>to test our visualizations For our research</td>\n      <td>0.380779</td>\n      <td>Ethan Ye</td>\n      <td>would love</td>\n      <td>to test Ethan Ye's visualizations For Ethan Ye's research</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "kb_df = pd.read_csv('/Users/taroaso/myprojects/OpenIE/wiki-research-l/output/full_replaced_triple_from_text_part.csv',index_col=0)\n",
    "kb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['<CAE4fJj-un1Um+3aE1jTe9b8WQZuFLMaaFmCJ9zNtzTkuUja0Rw@mail.gmail.com>',\n 'Thanks for your reply!',\n 'your',\n 'has',\n 'reply']\n555\n"
    }
   ],
   "source": [
    "# MinIEにかける\n",
    "import requests\n",
    "import json\n",
    "\n",
    "extractions_list = []\n",
    "for i,sentence in sentence_df['sentence'].items():\n",
    "    try:\n",
    "        response = requests.post('http://localhost:8080/minie/query', data=sentence)\n",
    "        result = response.json()\n",
    "        if result['facts'] == []:\n",
    "            pass\n",
    "        else:\n",
    "            for triple in result['facts']:\n",
    "                extractions_list.append([sentence_df['Message-ID'][i], sentence, triple['subject'], triple['predicate'], triple['object']])\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 整形結果をdataframeにする\n",
    "kb_df = pd.DataFrame(extractions_list, columns = ['message_id','sentence', 'arg1', 'rel', 'arg2s'])\n",
    "kb_df.head()\n",
    "# dataframeをcsv出力する\n",
    "kb_df.to_csv('wiki-research-l/output/minie_triple_from_text_part.csv')\n",
    "\n",
    "# dataframeをRDBのテーブルにする\n",
    "#from db import connect\n",
    "#engine = connect()\n",
    "#kb_df.to_sql(name='kb_wiki_research_l_text',con=engine,if_exists='replace',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# triple中の代名詞youの候補の辞書を作るために，Greetingsの行からYouの候補を取り出す．\n",
    "\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "you = {}\n",
    "for mail in bodies['Bodies']:\n",
    "    idx = mail['idx']\n",
    "    for greetings in mail['Greetings']:\n",
    "        doc = nlp(greetings[0])\n",
    "        you[idx] = [(X.text, X.label_) for X in doc.ents if X.label_ not in ['DATE','TIME','PERCENT','MONEY','QUANTITY','ORDINAL','CARDINAL']]\n",
    "        if you[idx] == []:\n",
    "            del you[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tripleのI, MY, ME, WE, OUR, USの代名詞をSenderに置き換えるための辞書\n",
    "refer_you = {}\n",
    "for idx, candidate in you.items():\n",
    "    message_id = mail_df[\"Message-ID\"][idx]\n",
    "    refer_you[message_id] = {\"YOU\":candidate[0][0], \"YOUR\":candidate[0][0] + '\\'s'}\n",
    "\n",
    "# tripleのI, MY, ME, WE, OUR, USの代名詞をSenderに置き換えるための辞書\n",
    "refer_pronoun = {}\n",
    "for row in kb_df.values:\n",
    "    message_id = row[0]\n",
    "    sender = mail_df[mail_df['Message-ID']==message_id]['From'].values[0]\n",
    "    start = re.search(r'(\\(.+\\))',sender).start()\n",
    "    end = re.search(r'(\\(.+\\))',sender).end()\n",
    "    sender = sender[start+1:end-1]\n",
    "    refer_pronoun[message_id]={'I':sender, 'MY':sender + '\\'s', 'ME':sender, 'WE':sender, 'OUR':sender + '\\'s', 'US':sender}\n",
    "\n",
    "# 2つの辞書を結合する\n",
    "for key, value in refer_you.items():\n",
    "    if key in refer_pronoun:\n",
    "        d = refer_pronoun[key]\n",
    "        d.update(value)\n",
    "        refer_pronoun[key] = d\n",
    "    else:\n",
    "        refer_pronoun[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Senderに置き換えるための辞書を使って実際に置き換える\n",
    "replaced_rows = []\n",
    "for row in kb_df.values:\n",
    "    message_id = row[0]\n",
    "    arg1 = row[2].split()\n",
    "    rel = row[3].split()\n",
    "    arg2s = row[4].split()\n",
    "    replaced = []\n",
    "    # arg1の置き換え\n",
    "    for i, word in enumerate(arg1):\n",
    "        sender = refer_pronoun[message_id].get(word.upper())\n",
    "        if sender is None:\n",
    "            continue\n",
    "        else:\n",
    "            arg1[i] = sender\n",
    "    new_arg1 = ' '.join(arg1)\n",
    "    replaced.append(new_arg1)\n",
    "    # relの置き換え\n",
    "    for i, word in enumerate(rel):\n",
    "        sender = refer_pronoun[message_id].get(word.upper())\n",
    "        if sender is None:\n",
    "            continue\n",
    "        else:\n",
    "            rel[i] = sender\n",
    "    new_rel = ' '.join(rel)\n",
    "    replaced.append(new_rel)\n",
    "    # arg2sの置き換え\n",
    "    for i, word in enumerate(arg2s):\n",
    "        sender = refer_pronoun[message_id].get(word.upper())\n",
    "        if sender is None:\n",
    "            continue\n",
    "        else:\n",
    "            arg2s[i] = sender\n",
    "    new_arg2s = ' '.join(arg2s)\n",
    "    replaced.append(new_arg2s)\n",
    "    # [new_arg1, new_rel, new_arg2s]を1行として追加\n",
    "    replaced_rows.append(replaced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_triples = pd.DataFrame(replaced_rows,columns=['new_arg1','new_rel','new_arg2s'])\n",
    "kb_df = pd.concat([kb_df, replaced_triples],axis=1)\n",
    "kb_df.to_csv('/Users/taroaso/myprojects/OpenIE/wiki-research-l/output/minie_triple_from_text_part.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from entityLinking import tagme, confidentAnnotations, mediaWiki\n",
    "\n",
    "entity_list = []\n",
    "for i, sentence in sentence_df['sentence'].items():\n",
    "    json_res = tagme(sentence)\n",
    "    for candidate in json_res['annotations']:\n",
    "        if candidate['rho'] >= 0.3:\n",
    "            entity_list.append([i, candidate['spot'],candidate['rho'],candidate['id'],candidate['title']])\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "# 抽出したentityをdataframeに格納する\n",
    "rows = []\n",
    "for row in entity_list:\n",
    "    rows.append([sentence_df['Message-ID'][row[0]], row[1], row[2], row[3], row[4]])\n",
    "entity_df = pd.DataFrame(rows,columns=['Message-ID','spot','rho','id','title'])\n",
    "entity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entity_df = pd.read_csv('wiki-research-l/output/entity_df.csv', index_col=0)\n",
    "entity_df[entity_df['rho'] < 0.3][0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extraction import entityExtraction\n",
    "\n",
    "ner_list = []\n",
    "for i, sentence in sentence_df['sentence'].items():\n",
    "    entities = entityExtraction(sentence)\n",
    "    ner_list.append(entities)\n",
    "len(ner_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}