{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, email\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import tokenize\n",
    "import pprint, re, time\n",
    "\n",
    "pd.options.display.max_colwidth = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loadFile import getFileList, getDirList, fileToDataFrame\n",
    "\n",
    "# ディレクトリ 内のメールファイルを読み込む\n",
    "directory_path = \"wiki-research-l/2020-July\"\n",
    "file_list = getFileList(directory_path)\n",
    "file_list.sort()\n",
    "\n",
    "# テキストファイルをデータフレームに格納する\n",
    "mail_df, thread_df = fileToDataFrame(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bodies = dict(Bodies=[])\n",
    "for idx, body in mail_df.loc[:,'Body'].items():\n",
    "    origin = []\n",
    "    greetings = dict(Greetings=[])\n",
    "    sentences = dict(Sentence=[])\n",
    "    captions = dict(Caption=[])\n",
    "    bulletlist = dict(Bulletlist=[])\n",
    "    ending = dict(Ending=[])\n",
    "    quotation = dict(Quotation=[])\n",
    "    footer = dict(Footer=[])\n",
    "    misc = dict(Misc=[])\n",
    "\n",
    "    lines = body.splitlines()\n",
    "    for num, line in enumerate(lines):\n",
    "        if re.match(r'\\[G\\]',line) is not None:\n",
    "            greetings['Greetings'].append({num:line[3:]})\n",
    "            origin.append(line[3:])\n",
    "        elif re.match(r'\\[S\\]',line) is not None:\n",
    "            sentences['Sentence'].append({num:line[3:]})\n",
    "            origin.append(line[3:])\n",
    "        elif re.match(r'\\[C\\]',line) is not None:\n",
    "            captions['Caption'].append({num:line[3:]})\n",
    "            origin.append(line[3:])\n",
    "        elif re.match(r'\\[B\\]',line) is not None:\n",
    "            bulletlist['Bulletlist'].append({num:line[3:]})\n",
    "            origin.append(line[3:])\n",
    "        elif re.match(r'\\[E\\]',line) is not None:\n",
    "            ending['Ending'].append({num:line[3:]})\n",
    "            origin.append(line[3:])\n",
    "        elif re.match(r'\\[Q\\]',line) is not None:\n",
    "            quotation['Quotation'].append({num:line[3:]})\n",
    "            origin.append(line[3:])\n",
    "        elif re.match(r'\\[F\\]',line) is not None:\n",
    "            footer['Footer'].append({num:line[3:]})\n",
    "            origin.append(line[3:])\n",
    "        elif re.match(r'\\[M\\]',line) is not None:\n",
    "            misc['Misc'].append({num:line[3:]})\n",
    "            origin.append(line[3:])\n",
    "        else: #空白行に対応する\n",
    "            continue\n",
    "    originbody = ' '.join(origin)\n",
    "    bodies['Bodies'].append({'idx':idx, 'countrows':len(lines), 'body':originbody, **greetings, **sentences, **captions, **bulletlist, **ending, **quotation, **footer, **misc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#　bodiesのsentenceのvalueから複数文のテキストを作る\n",
    "s_list = []\n",
    "for i in bodies['Bodies']:  #1通ずつ取り出す\n",
    "    text = ''\n",
    "    for j in i['Sentence']: #1行{行番号:文}ずつ取り出し，複数文が含まれた1つの文字列にする\n",
    "        text = text + list(j.values())[0] + ' '\n",
    "    s_list.append(text) #1通ごとの自然文のテキストをリストに格納する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# センテンスのdataframeを作る\n",
    "sentence_list = []\n",
    "# 文章全体に対する前処理\n",
    "for i, content in enumerate(s_list):\n",
    "    sentences = tokenize.sent_tokenize(content)\n",
    "    # 文に対する前処理\n",
    "    for j, sentence in enumerate(sentences):\n",
    "        sentence = re.sub(r'\\s{2,}',' ',sentence)\n",
    "        sentence_list.append([mail_df['Message-ID'][i],sentence])\n",
    "sentence_df = pd.DataFrame(sentence_list,columns=['Message-ID','sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                             Message-ID  \\\n0  <CAE4fJj-un1Um+3aE1jTe9b8WQZuFLMaaFmCJ9zNtzTkuUja0Rw@mail.gmail.com>   \n1  <CAE4fJj-un1Um+3aE1jTe9b8WQZuFLMaaFmCJ9zNtzTkuUja0Rw@mail.gmail.com>   \n2  <CAE4fJj-un1Um+3aE1jTe9b8WQZuFLMaaFmCJ9zNtzTkuUja0Rw@mail.gmail.com>   \n3  <CAE4fJj-un1Um+3aE1jTe9b8WQZuFLMaaFmCJ9zNtzTkuUja0Rw@mail.gmail.com>   \n4  <CAE4fJj_b7k8yeqmz19a-seo3gtL9Mg1nvQO0oPUtrxvCFMkEaw@mail.gmail.com>   \n\n                                                                                                          sentence  \n0                                                                                           Thanks for your reply!  \n1  It's a great suggestion to include a list of ORES based tools for people who are not familiar with ORES itself.  \n2                                    For our research, we would love to interview you and test our visualizations.  \n3                               Please let me know what times will work best for you so we can schedule a meeting.  \n4                                                                                           Thanks for clarifying.  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Message-ID</th>\n      <th>sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;CAE4fJj-un1Um+3aE1jTe9b8WQZuFLMaaFmCJ9zNtzTkuUja0Rw@mail.gmail.com&gt;</td>\n      <td>Thanks for your reply!</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;CAE4fJj-un1Um+3aE1jTe9b8WQZuFLMaaFmCJ9zNtzTkuUja0Rw@mail.gmail.com&gt;</td>\n      <td>It's a great suggestion to include a list of ORES based tools for people who are not familiar with ORES itself.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;CAE4fJj-un1Um+3aE1jTe9b8WQZuFLMaaFmCJ9zNtzTkuUja0Rw@mail.gmail.com&gt;</td>\n      <td>For our research, we would love to interview you and test our visualizations.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;CAE4fJj-un1Um+3aE1jTe9b8WQZuFLMaaFmCJ9zNtzTkuUja0Rw@mail.gmail.com&gt;</td>\n      <td>Please let me know what times will work best for you so we can schedule a meeting.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;CAE4fJj_b7k8yeqmz19a-seo3gtL9Mg1nvQO0oPUtrxvCFMkEaw@mail.gmail.com&gt;</td>\n      <td>Thanks for clarifying.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "sentence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# OpenIEにかける\n",
    "from pyopenie import OpenIE5\n",
    "extractor = OpenIE5('http://localhost:8000')\n",
    "\n",
    "extractions_list = []\n",
    "for sentence in sentence_list:\n",
    "    try:\n",
    "        extractions = extractor.extract(sentence)\n",
    "        extractions_list.append(extractions)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# OIEの抽出結果を整形する\n",
    "rows = []\n",
    "for extractions in extractions_list:\n",
    "    if extractions == []:\n",
    "        pass\n",
    "    else:\n",
    "        for extraction in extractions:\n",
    "            sentence = extraction['sentence']\n",
    "            confidence = extraction['confidence']\n",
    "            arg1 = extraction['extraction']['arg1']['text']\n",
    "            rel = extraction['extraction']['rel']['text']\n",
    "            arg2s_list = []\n",
    "            for arg2 in extraction['extraction']['arg2s']:\n",
    "                arg2s_list.append(arg2['text'])\n",
    "            arg2s = ' '.join(map(str, arg2s_list))\n",
    "            row = [sentence, arg1, rel, arg2s, confidence]\n",
    "            rows.append(row)\n",
    "\n",
    "# 整形結果をdataframeにする\n",
    "kb_df = pd.DataFrame(rows, columns = ['sentence', 'arg1', 'rel', 'arg2s', 'confidence'])\n",
    "\n",
    "# dataframeをcsv出力する\n",
    "kb_df.to_csv('wiki-research-l/output/triple_from_text_part.csv')\n",
    "\n",
    "# dataframeをRDBのテーブルにする\n",
    "'''\n",
    "'''\n",
    "from db import connect\n",
    "engine = connect()\n",
    "kb_df.to_sql(name='kb_wiki_research_l_text',con=engine,if_exists='replace',index=None)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from entityLinking import tagme, confidentAnnotations, mediaWiki\n",
    "\n",
    "entity_list = []\n",
    "for i, sentence in sentence_df['sentence'].items():\n",
    "    json_res = tagme(sentence)\n",
    "    for candidate in json_res['annotations']:\n",
    "        if candidate['rho'] > 0.5:\n",
    "            entity_list.append([i, candidate['spot'],candidate['rho'],candidate['id'],candidate['title']])\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for row in entity_list:\n",
    "    rows.append([sentence_df['Message-ID'][row[0]], row[1], row[2], row[3], row[4]])\n",
    "entity_df = pd.DataFrame(rows,columns=['Message-ID','spot','rho','id','title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                             Message-ID  \\\n0  <CALeA2c9GW9BFSMetuSCDWLbm2iGG1xM7Bp0R2A9-JJF2_7Xrwg@mail.gmail.com>   \n1  <CAD_=H2LWP6n5COjqc-DEw59feJGxXBpJLen4m7BtPT5MfcJrpg@mail.gmail.com>   \n2  <CAD_=H2LWP6n5COjqc-DEw59feJGxXBpJLen4m7BtPT5MfcJrpg@mail.gmail.com>   \n3  <CAD_=H2LWP6n5COjqc-DEw59feJGxXBpJLen4m7BtPT5MfcJrpg@mail.gmail.com>   \n4  <CAD_=H2LWP6n5COjqc-DEw59feJGxXBpJLen4m7BtPT5MfcJrpg@mail.gmail.com>   \n\n                   spot       rho        id                        title  \n0                 https  0.507675     13443  Hypertext Transfer Protocol  \n1  Wikimedia Foundation  0.594803  18618509         Wikimedia Foundation  \n2   University of Turin  0.634261    453828          University of Turin  \n3           Phabricator  0.567908  40879657                  Phabricator  \n4  Wikimedia Foundation  0.601363  18618509         Wikimedia Foundation  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Message-ID</th>\n      <th>spot</th>\n      <th>rho</th>\n      <th>id</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;CALeA2c9GW9BFSMetuSCDWLbm2iGG1xM7Bp0R2A9-JJF2_7Xrwg@mail.gmail.com&gt;</td>\n      <td>https</td>\n      <td>0.507675</td>\n      <td>13443</td>\n      <td>Hypertext Transfer Protocol</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;CAD_=H2LWP6n5COjqc-DEw59feJGxXBpJLen4m7BtPT5MfcJrpg@mail.gmail.com&gt;</td>\n      <td>Wikimedia Foundation</td>\n      <td>0.594803</td>\n      <td>18618509</td>\n      <td>Wikimedia Foundation</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;CAD_=H2LWP6n5COjqc-DEw59feJGxXBpJLen4m7BtPT5MfcJrpg@mail.gmail.com&gt;</td>\n      <td>University of Turin</td>\n      <td>0.634261</td>\n      <td>453828</td>\n      <td>University of Turin</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;CAD_=H2LWP6n5COjqc-DEw59feJGxXBpJLen4m7BtPT5MfcJrpg@mail.gmail.com&gt;</td>\n      <td>Phabricator</td>\n      <td>0.567908</td>\n      <td>40879657</td>\n      <td>Phabricator</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;CAD_=H2LWP6n5COjqc-DEw59feJGxXBpJLen4m7BtPT5MfcJrpg@mail.gmail.com&gt;</td>\n      <td>Wikimedia Foundation</td>\n      <td>0.601363</td>\n      <td>18618509</td>\n      <td>Wikimedia Foundation</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "entity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}